<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Academic group name</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Academic group name</description>
    <generator>Hugo</generator>
    <language>en</language>
    <copyright>&amp;copy; Nlp Group Bit, 2024</copyright>
    <lastBuildDate>Sat, 20 Jul 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Several papers from the lab accepted by ACL 2024</title>
      <link>http://localhost:1313/post/post1/</link>
      <pubDate>Sat, 20 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/post1/</guid>
      <description>In July 2024, 2 papers from the academic group were accepted at the ACL 2024 conference. ACL is the Association for Computational Linguistics, which is the most influential academic organisation in the field of computational linguistics, and is the most important international conference in the field of computational linguistics, and is the only Class A conference in computational linguistics recommended by CCF.&#xA;The brief description of the accepted papers is given below:</description>
    </item>
    <item>
      <title>Word Matters: What Influences Domain Adaptation in Summarization?</title>
      <link>http://localhost:1313/publication/paper1/</link>
      <pubDate>Fri, 21 Jun 2024 02:15:49 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper1/</guid>
      <description></description>
    </item>
    <item>
      <title>Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey</title>
      <link>http://localhost:1313/publication/paper3/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper3/</guid>
      <description></description>
    </item>
    <item>
      <title>Stage-wise Stylistic Headline Generation: Style Generation and Summarized Content Insertion</title>
      <link>http://localhost:1313/publication/paper4/</link>
      <pubDate>Sat, 01 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper4/</guid>
      <description></description>
    </item>
    <item>
      <title>DRMSpell: Dynamically Reweighting Multimodality for  Chinese Spelling Correction</title>
      <link>http://localhost:1313/publication/paper8/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper8/</guid>
      <description></description>
    </item>
    <item>
      <title>Latent representation discretization for unsupervised text style generation</title>
      <link>http://localhost:1313/publication/paper17/</link>
      <pubDate>Fri, 01 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper17/</guid>
      <description></description>
    </item>
    <item>
      <title>MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications</title>
      <link>http://localhost:1313/publication/paper2/</link>
      <pubDate>Fri, 06 Oct 2023 02:15:49 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper2/</guid>
      <description></description>
    </item>
    <item>
      <title>Domain adaptation and Summary Distillation for Unsupervised Query Focused Summarization</title>
      <link>http://localhost:1313/publication/paper6/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper6/</guid>
      <description></description>
    </item>
    <item>
      <title>TemplateGEC: Improving Grammatical Error Correction with Detection Template</title>
      <link>http://localhost:1313/publication/paper7/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper7/</guid>
      <description></description>
    </item>
    <item>
      <title>Ask to Understand: Question Generation for Multi-hop Question Answering</title>
      <link>http://localhost:1313/publication/paper23/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper23/</guid>
      <description></description>
    </item>
    <item>
      <title>Unsupervised Style Transfer in News Headlines via Discrete Style Space</title>
      <link>http://localhost:1313/publication/paper24/</link>
      <pubDate>Sat, 01 Apr 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper24/</guid>
      <description></description>
    </item>
    <item>
      <title>TopicBERT: A Topic-Enhanced Neural Language Model Fine-Tuned for Sentiment Classification</title>
      <link>http://localhost:1313/publication/paper16/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper16/</guid>
      <description></description>
    </item>
    <item>
      <title>Interpretable modular knowledge reasoning for machine reading comprehension</title>
      <link>http://localhost:1313/publication/paper14/</link>
      <pubDate>Fri, 01 Jul 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper14/</guid>
      <description></description>
    </item>
    <item>
      <title>Building Knowledge-Grounded Dialogue Systems with Graph-Based Semantic Modeling</title>
      <link>http://localhost:1313/publication/paper11/</link>
      <pubDate>Wed, 27 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper11/</guid>
      <description></description>
    </item>
    <item>
      <title>PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization</title>
      <link>http://localhost:1313/publication/paper9/</link>
      <pubDate>Sat, 09 Apr 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper9/</guid>
      <description></description>
    </item>
    <item>
      <title>TCM-SD: A Benchmark for Probing Syndrome Differentiation via Natural Language Processing</title>
      <link>http://localhost:1313/publication/paper12/</link>
      <pubDate>Mon, 21 Mar 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper12/</guid>
      <description></description>
    </item>
    <item>
      <title>To be Closer: Learning to Link up Aspects with Opinions</title>
      <link>http://localhost:1313/publication/paper27/</link>
      <pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper27/</guid>
      <description></description>
    </item>
    <item>
      <title>Unifying Cross-lingual Summarization and Machine Translation with Compression Rate</title>
      <link>http://localhost:1313/publication/paper5/</link>
      <pubDate>Fri, 15 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper5/</guid>
      <description></description>
    </item>
    <item>
      <title>SKR-QA: Semantic ranking and knowledge revise for multi-choice question answering</title>
      <link>http://localhost:1313/publication/paper15/</link>
      <pubDate>Tue, 12 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper15/</guid>
      <description></description>
    </item>
    <item>
      <title>Cross-Lingual Abstractive Summarization with Limited Parallel Resources</title>
      <link>http://localhost:1313/publication/paper10/</link>
      <pubDate>Fri, 28 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper10/</guid>
      <description></description>
    </item>
    <item>
      <title>Extracting salient features from convolutional discriminative filter</title>
      <link>http://localhost:1313/publication/paper26/</link>
      <pubDate>Sun, 02 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper26/</guid>
      <description></description>
    </item>
    <item>
      <title>Extracting salient features from convolutional discriminative filters</title>
      <link>http://localhost:1313/publication/paper20/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper20/</guid>
      <description></description>
    </item>
    <item>
      <title>Jointly Learning Topics in Sentence Embedding for Document Summarization</title>
      <link>http://localhost:1313/publication/paper18/</link>
      <pubDate>Wed, 01 Apr 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper18/</guid>
      <description></description>
    </item>
    <item>
      <title>Concept Pointer Network for Abstractive Summarization</title>
      <link>http://localhost:1313/publication/paper13/</link>
      <pubDate>Fri, 18 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper13/</guid>
      <description></description>
    </item>
    <item>
      <title>Neural Variational Correlated Topic Modeling</title>
      <link>http://localhost:1313/publication/paper19/</link>
      <pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper19/</guid>
      <description></description>
    </item>
    <item>
      <title>Task-oriented Word Embedding for Text Classification</title>
      <link>http://localhost:1313/publication/paper22/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper22/</guid>
      <description></description>
    </item>
    <item>
      <title>Semantic Structure-Based Word Embedding by Incorporating Concept Convergence and Word Divergence</title>
      <link>http://localhost:1313/publication/paper25/</link>
      <pubDate>Fri, 02 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper25/</guid>
      <description></description>
    </item>
    <item>
      <title>Member 01</title>
      <link>http://localhost:1313/leader/leader1/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/leader/leader1/</guid>
      <description>Yang Gao, Doctoral Supervisor, primarily engages in large language model training, automatic text generation technologies, and the application and transformation of these technologies. She has published over 60 high-level papers in international journals and conferences, including ACL, AAAI, WWW, IJCAI, EMNLP, TKDE and others. She has served as a chair in the text generation area for conferences like EMNLP and COLING, as an editorial board member for journals like Web Intelligence and Natural Language Processing Journal, as a program committee member for international conferences such as AAAI, ACL, EMNLP, NAACL, ICDM, and as a reviewer for journals including TNNLS and Computing Surveys.</description>
    </item>
    <item>
      <title>Member 01</title>
      <link>http://localhost:1313/member/leader1/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/leader1/</guid>
      <description>Yang Gao, Doctoral Supervisor, primarily engages in large language model training, automatic text generation technologies, and the application and transformation of these technologies. She has published over 60 high-level papers in international journals and conferences, including ACL, AAAI, WWW, IJCAI, EMNLP, TKDE and others. She has served as a chair in the text generation area for conferences like EMNLP and COLING, as an editorial board member for journals like Web Intelligence and Natural Language Processing Journal, as a program committee member for international conferences such as AAAI, ACL, EMNLP, NAACL, ICDM, and as a reviewer for journals including TNNLS and Computing Surveys.</description>
    </item>
    <item>
      <title>Member 02</title>
      <link>http://localhost:1313/member/member2/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member2/</guid>
      <description>I am a sixth-year PhD student. I am interested in instruction fine-tuning and in-context learning. I often exercise and read to enrich my extracurricular life.</description>
    </item>
    <item>
      <title>Member 03</title>
      <link>http://localhost:1313/member/member3/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member3/</guid>
      <description>I used to study Cross-lingual Summarization to investigate how to better generate text with low-resource data. As large language models (LLMs) continue to gain popularity, I am curious about why they are competent in so many challenging tasks. Hence, I have begun to think of LLMs as natural objects. By studying their working mechanisms and characteristics, I aim to understand these models more deeply and use these insights to improve them in terms of their generation quality, controllability, and safety.</description>
    </item>
    <item>
      <title>Member 04</title>
      <link>http://localhost:1313/member/member4/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member4/</guid>
      <description>Hi, my name is Yuhang Liu. My research primarily focuses on knowledge conflict in LLMs, model calibration, and retrieval-augmented generation. I am passionate about advancing the capabilities and understanding of AI, and I aspire to become an outstanding contributor in this field.</description>
    </item>
    <item>
      <title>Member 05</title>
      <link>http://localhost:1313/member/member5/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member5/</guid>
      <description>Yizhe Yang (Êù®ÊØÖÂì≤) is a third-year Ph.D. student at the School of Computer Science and Technology, Beijing Institute of Technology (2021-present), where he is under the guidance of Prof. Heyan Huang and Prof. Yang Gao. He earned his bachelor&amp;rsquo;s degree from Beijing Institute of Technology (2016-2020). Following his bachelor‚Äôs, he pursued a master&amp;rsquo;s degree (2020-2021) before transitioning into a combined master-doctoral program. During his studies, he fortunately had the opportunity to work under the supervision of Prof.</description>
    </item>
    <item>
      <title>Member 06</title>
      <link>http://localhost:1313/member/member6/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member6/</guid>
      <description>Hi, I am Jiawei Li. My research has been primarily focused on the reasoning capabilities of LLMs, the efficient tuning of LLMs, and the model evolution. I hope I can be a reliable person. Thank you.</description>
    </item>
    <item>
      <title>Member 09</title>
      <link>http://localhost:1313/member/member9/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member9/</guid>
      <description>Hi, my name is Bowen Ren. I am currently focused on research in LLM training and self-evolution, and I have a strong interest in agents and LLM applications. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 10</title>
      <link>http://localhost:1313/member/member10/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member10/</guid>
      <description>üëãüèªI&amp;rsquo;m Huashan Sun.ü•πMy research currently specializes in continual learning and language style modeling for LLMs, with a keen interest in model interpretability and trustworthiness.I&amp;rsquo;m an INTJü§´, passionate about üì∏photography and ü•ætravel, investing my time in activities that captivate my interest.</description>
    </item>
    <item>
      <title>Member 11</title>
      <link>http://localhost:1313/member/member11/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member11/</guid>
      <description>Hi, I am Xinyue Liang. My current research interests lie in the mathematical reasoning abilities of LLMs and reinforcement learning. I am an ISTJ/INTJ who enjoys sports and movies, with a enthusiasm for badminton.</description>
    </item>
    <item>
      <title>Member 12</title>
      <link>http://localhost:1313/member/member12/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member12/</guid>
      <description>I am Siming Liu and I am currently studying the alignment of LLMs while exploring its multi-task abilities. I am also working on a codebase for LLM alignment. Besides study and research, I developed a consuming passion in music.</description>
    </item>
    <item>
      <title>Member 13</title>
      <link>http://localhost:1313/member/member13/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member13/</guid>
      <description>Hello, my name is Yuhao Ye. My current research focuses on studying the shifts in the output distribution of large language models after fine-tuning, and exploring methods to analyze these shifts. In addition to research, I am interested in table tennis. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 14</title>
      <link>http://localhost:1313/member/member14/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member14/</guid>
      <description>Hello, my name is Siyu Miao. My current research focuses on the factors affecting domain transferring of large language models after fine-tuning, and exploring methods to quantify these shifts. In addition to research, I am interested in badminton. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 15</title>
      <link>http://localhost:1313/member/member15/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member15/</guid>
      <description>Hello, my name is Xingpeng Si. My current research focuses on studying the shifts in the output distribution of large language models after fine-tuning, and exploring methods to analyze these shifts. In addition to research, I am interested in table tennis. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 16</title>
      <link>http://localhost:1313/member/member16/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member16/</guid>
      <description>Hello, my name is Yixiao Wu. My current research focuses on language style modeling for LLMs. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 17</title>
      <link>http://localhost:1313/member/member17/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member17/</guid>
      <description>Hello, my name is Si Xingpeng. My current research focuses on improving the generalization ability of large language models on downstream tasks. In addition for the sake of my research, I am interested in table tennis. I hope to make meaningful discoveries in my research.</description>
    </item>
    <item>
      <title>Member 18</title>
      <link>http://localhost:1313/member/member18/</link>
      <pubDate>Tue, 12 Jul 2016 15:52:22 +0200</pubDate>
      <guid>http://localhost:1313/member/member18/</guid>
      <description>Hi, I am Yiguan Lin. My current research mainly focuses on parameter merging in large language models, exploring ways to enhance the capabilities of large models without the need for additional training.</description>
    </item>
    <item>
      <title>Pattern-based Topics for Document Modelling in Information Filtering</title>
      <link>http://localhost:1313/publication/paper21/</link>
      <pubDate>Fri, 19 Dec 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/paper21/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>Sed extemplo conantur et Cnosia harundine lyra Agros metitur venatibus catenis quippe honorem tuorum Lorem markdownum finemque prunaque longe et sunt. Sed super aulaea in Paridis noctisque cubile? Iacit coetus, vastatoremque dedit; Vidi magna, recurvatis copia. Quod sit; per cingo tamen Hyperionis si vacat inclitus instabat curaque arma saxea, naturaeque pondere quaeque aer!&#xA;Agros apertum aliis dominaeque rapidus Prima nulla est Hortatibus voto Anum istis praefertur est Quaque coeptis lumina mea nuda dentes semine agitavit, caesique voluptas.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/approach/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/approach/</guid>
      <description>Et malis vellet tellus deseruere in credant Inde sidera moenia lacertis nomen nostra membra Lorem markdownum miranti. Sonus faciunt omnibus frustra: illa possem ad regio Anubis tamen. Sustulerat debent fluviis herbis attollere rogus et formae nitentem avellere motis clipeus Achilles felix videam undas. Posuit haec ipse posse.&#xA;Ore fame mons Olympi tantae stringit columbas proxima habebat, longius alta non. Haeserat gerunt detinuit genis est huc, dixit tam dumque nitidum.&#xA;Cristata causam Triones moenia habentem subito utentem Astraea castris contentus nisi leve eum invia Inferiusque capta cognoscenda flaventi locuta notavi fallere Moriens scripsi ictus tuo cum Tarpeias insurgens summo sinistra vertice, in neve utroque exempla Cyparissus tanta tecti terras.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/mission/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/mission/</guid>
      <description>Auras queritur facientes dixit venti sustinui E in mora Lorem markdownum poenaque nuper destituit silendo quoniam, nec ait consorte membra, figuram hanc cum. Manifesta vitae facies exiguumque iunctam dictis. Vidit eadem, hanc cum descendit sinu misit quem fecit, positisque pastorve. Missus solos potentia in erant noctem est!&#xA;if (dvdProcessorVolume &amp;lt; mpegProcess(slashdot, gigahertz)) {&#xD;transferAnsiBotnet.and(logSoftware, hsfClipboardSubnet.queue_publishing(&#xD;systemMemory, 5, yahoo));&#xD;} else {&#xD;swappableIpv -= spoolingAdwareCrossplatform;&#xD;extranetAppArchitecture(1, dtd_rpc_font(45, 67, development_sli));&#xD;}&#xD;antivirus_ipv = touchscreenFiosGrep.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/</guid>
      <description>Modo est Non sub haedum tenet Lorem markdownum esse diversa quoque vocavit, quam! Vires tibi axis dum spolium vaticinor fulminis, a dixere attrahit generisque tamen?&#xA;Petit invergens iram praetendat iam Mecum res curva iunctura silvis hoc leonum Iacent gemitum quos Non est duram mitis sonat proculcat tumulos Alce bimembres Dauni, cur ex voces referam adunco in sors. Manibusque poples prodidit lata tantum quem suos ratae Aeginae sederunt degenerat Bacchus descendere, patriisque ieiunia.</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/vacancy/vacancy1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/vacancy/vacancy1/</guid>
      <description>You can write $\LaTeX$ and Markdown here.&#xA;Minyae adgnoscitque fugiebat parentis ausum superos huius Ait erili meruisse iactatis omnibus erat Lorem markdownum natis, ipsi ipsi aut relictus saxo comitantibus aegro amori verba fugisse mira mortisque leones! Prior sui liquidissimus leve properandum totidem studio, refert magno, me quibus. Sternitur discordia summaque, si deus in undam et vulnere dirusque est felices pallam miserere curvamine comites. Tegumenque decipit suis, poscitur una dea sumus adnuerant, gerebat est edam plura.</description>
    </item>
  </channel>
</rss>
