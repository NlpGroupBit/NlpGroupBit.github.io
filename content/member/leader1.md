+++
bio = ""
date = "2016-07-12T15:52:22+02:00"
id = "member1"
interests = ["Large laguage model", "Self-Evolution", "Text Generation", "Technology Application Transformation"]
name = "Yang Gao"
portrait = "/portraits/gy.jpg"
short_bio = ""
short_name = ""
title = "Member 01"

[[social]]
    icon = "envelope"
    icon_pack = "fa"
    link = "gyang@bit.edu.cn"

[[education]]
    course = "PhD in Data Science"
    institution = 'Queensland University of Technology'

[[organizations]]
    name = "Beijing Institute of Technology"
    role = "Associate Professor"

+++

> Yang Gao, Doctoral Supervisor, primarily engages in large language model training, automatic text generation technologies, and the application and transformation of these technologies. She has published over 60 high-level papers in international journals and conferences, including ACL, AAAI, WWW, IJCAI, EMNLP, TKDE and others. She has served as a chair in the text generation area for conferences like EMNLP and COLING, as an editorial board member for journals like Web Intelligence and Natural Language Processing Journal, as a program committee member for international conferences such as AAAI, ACL, EMNLP, NAACL, ICDM, and as a reviewer for journals including TNNLS and Computing Surveys. She has led the development of the Mingde Foundation large language model (MindLLM) trained from scratch and the construction of domestic ecological large models. She has open-sourced the "on-device" conversational large model and deployed intelligent e-government services enhanced by retrieval-augmented large models. As a participant, she has received the First Prize of the Science and Technology Progress Award from the China Institute of Electronics and the Second Prize of the National Defense Science and Technology Progress Award. A visiting scholar at the University of Edinburgh, the vice secretary-general of the Natural Language Generation and Intelligent Writing Committee of the China Society of Chinese Information Processing, a member of the China Society of Chinese Information Processing Youth Working Committee, and a member of the CCF Large Model Forum Executive Committee.

