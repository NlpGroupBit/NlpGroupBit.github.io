+++
bio = ""
date = "2016-07-12T15:52:22+02:00"
id = "member3"
interests = ["large language models"]
name = "Yu Bai"
portrait = "/portraits/by.jpg"
short_bio = ""
short_name = ""
title = "Member 03"

[[social]]
    icon = "envelope"
    icon_pack = "fa"
    link = "ybai@bit.edu.cn"

[[education]]
    course = "PhD Student in Computer Science"
    institution = 'Beijing Institute of Technology'

[[organizations]]
    name = "Beijing Institute of Technology"
    role = "PhD Student"

+++

> I used to study Cross-lingual Summarization to investigate how to better generate text 
> with low-resource data. As large language models (LLMs) continue to gain popularity, I am
>  curious about why they are competent in so many challenging tasks. Hence, I have begun to 
> think of LLMs as natural objects. By studying their working mechanisms and 
> characteristics, I aim to understand these models more deeply and use these insights to 
> improve them in terms of their generation quality, controllability, and safety.
