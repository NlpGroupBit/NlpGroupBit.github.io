+++
abstract = "A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-to-sequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distantly-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC-2004 and Gigaword datasets. A human evaluation of the model's abstractive abilities also supports the quality of the summaries produced within this framework."
date = "2019-10-18"
image = ""
image_preview = ""
math = false
publication = "EMNLP 2019"
publication_short = ""
selected = false
title = "Concept Pointer Network for Abstractive Summarization"
url_dataset = ""
url_pdf = "https://arxiv.org/abs/1910.08486"
url_slides = ""
url_video = ""

[[authors]]
    name = "Wenbo Wang"
    is_member = false
[[authors]]
    is_member = true
    id = "member1"
[[authors]]
    name = "Heyan Huang"
    is_member = false
[[authors]]
    name = "Yuxiang Zhou"
    is_member = false

+++
